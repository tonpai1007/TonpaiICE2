// voiceService.js - FIXED: Only use AI correction when needed

const speech = require('@google-cloud/speech');
const { configManager, loadGoogleCredentials } = require('./config');
const { Logger } = require('./logger');
const { generateWithGemini, isGeminiAvailable } = require('./aiServices');
const { getStockCache, getCustomerCache } = require('./cacheManager');
const { stockVectorStore } = require('./vectorStore');

let speechClient = null;

// ============================================================================
// INITIALIZE GOOGLE SPEECH
// ============================================================================

function initializeSpeechClient() {
  if (speechClient) return speechClient;
  
  try {
    const credentials = loadGoogleCredentials();
    
    speechClient = new speech.SpeechClient({
      credentials
    });
    
    Logger.success('Google Speech-to-Text initialized');
    return speechClient;
  } catch (error) {
    Logger.error('Failed to initialize Google Speech', error);
    throw error;
  }
}

// ============================================================================
// BUILD SPEECH CONTEXT (VOCABULARY HINTS)
// ============================================================================

function buildSpeechContext() {
  const stockCache = getStockCache();
  const customerCache = getCustomerCache();
  
  const phrases = new Set();

  // Add all customer names
  customerCache.forEach(customer => {
    phrases.add(customer.name);
  });

  // Add all product names
  stockCache.forEach(item => {
    phrases.add(item.item);
  });

  // Add common keywords
  const keywords = [
    '‡∏ô‡πâ‡∏≥‡πÅ‡∏Ç‡πá‡∏á', '‡∏´‡∏•‡∏≠‡∏î', '‡∏ö‡∏î', '‡πÅ‡∏ú‡πà‡∏ô', '‡πÄ‡∏Å‡∏£‡πá‡∏î',
    '‡πÉ‡∏´‡∏ç‡πà', '‡πÄ‡∏•‡πá‡∏Å', '‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î', '‡∏´‡∏¢‡∏≤‡∏ö',
    '‡∏ñ‡∏∏‡∏á', '‡∏Å‡∏£‡∏∞‡∏™‡∏≠‡∏ö', '‡∏Ç‡∏ß‡∏î', '‡∏Å‡∏£‡∏∞‡∏õ‡πã‡∏≠‡∏á',
    '‡∏™‡∏±‡πà‡∏á', '‡∏ã‡∏∑‡πâ‡∏≠', '‡∏™‡πà‡∏á‡πÇ‡∏î‡∏¢', '‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï',
    '‡∏û‡∏µ‡πà', '‡∏ô‡πâ‡∏≠‡∏á', '‡∏Ñ‡∏∏‡∏ì', '‡∏•‡∏∏‡∏á', '‡∏õ‡πâ‡∏≤'
  ];
  
  keywords.forEach(word => phrases.add(word));

  const finalPhrases = Array.from(phrases).slice(0, 500);
  Logger.success(`Speech context: ${finalPhrases.length} phrases`);
  
  return finalPhrases;
}

// ============================================================================
// DETECT AUDIO FORMAT
// ============================================================================

function detectAudioFormat(buffer) {
  if (buffer[0] === 0x4F && buffer[1] === 0x67 && buffer[2] === 0x67 && buffer[3] === 0x53) {
    return 'OGG_OPUS';
  }
  
  if (buffer[0] === 0x1A && buffer[1] === 0x45 && buffer[2] === 0xDF && buffer[3] === 0xA3) {
    return 'WEBM_OPUS';
  }
  
  if (buffer[4] === 0x66 && buffer[5] === 0x74 && buffer[6] === 0x79 && buffer[7] === 0x70) {
    return 'MP4';
  }
  
  return 'OGG_OPUS';
}

// ============================================================================
// TRANSCRIBE AUDIO WITH GOOGLE SPEECH
// ============================================================================

async function transcribeAudioWithGoogle(audioBuffer) {
  try {
    const client = initializeSpeechClient();
    const phrases = buildSpeechContext();
    
    const audioFormat = detectAudioFormat(audioBuffer);
    const audioSize = (audioBuffer.length / 1024).toFixed(1);
    
    Logger.info(`Transcribing with Google: ${audioSize}KB (${audioFormat})`);
    
    if (audioBuffer.length < 1000) {
      throw new Error('Audio file too small (likely empty or corrupted)');
    }
    
    if (audioBuffer.length > 10 * 1024 * 1024) {
      throw new Error('Audio file too large (max 10MB)');
    }
    
    const audio = {
      content: audioBuffer.toString('base64')
    };
    
    const configs = [
      {
        name: 'OGG_OPUS (LINE Default)',
        encoding: 'OGG_OPUS',
        sampleRateHertz: 16000,
      },
      {
        name: 'WEBM_OPUS',
        encoding: 'WEBM_OPUS',
        sampleRateHertz: 48000,
      },
      {
        name: 'LINEAR16',
        encoding: 'LINEAR16',
        sampleRateHertz: 16000,
      }
    ];
    
    let lastError = null;
    
    for (const configVariant of configs) {
      try {
        Logger.info(`Trying config: ${configVariant.name}`);
        
        const config = {
          encoding: configVariant.encoding,
          sampleRateHertz: configVariant.sampleRateHertz,
          languageCode: 'th-TH',
          alternativeLanguageCodes: ['en-US'],
          enableAutomaticPunctuation: true,
          model: 'default',
          useEnhanced: true,
          maxAlternatives: 3,
          speechContexts: [{
            phrases: phrases,
            boost: 20
          }],
          enableWordConfidence: true,
          enableWordTimeOffsets: true
        };
        
        const request = {
          audio: audio,
          config: config
        };
        
        const [response] = await client.recognize(request);
        
        if (!response.results || response.results.length === 0) {
          Logger.warn(`No results with ${configVariant.name}`);
          lastError = new Error(`No transcription results with ${configVariant.name}`);
          continue;
        }
        
        const result = response.results[0];
        const alternatives = result.alternatives || [];
        
        if (alternatives.length === 0) {
          Logger.warn(`No alternatives with ${configVariant.name}`);
          continue;
        }
        
        const bestAlternative = alternatives[0];
        const transcription = bestAlternative.transcript;
        const confidence = bestAlternative.confidence || 0;
        
        if (alternatives.length > 1) {
          Logger.info('Alternative transcriptions:');
          alternatives.forEach((alt, idx) => {
            Logger.info(`  ${idx + 1}. "${alt.transcript}" (${(alt.confidence * 100).toFixed(1)}%)`);
          });
        }
        
        if (!transcription || transcription.trim().length === 0) {
          Logger.warn('Empty transcription');
          continue;
        }
        
        Logger.success(`‚úÖ Transcribed with ${configVariant.name}: "${transcription}" (${(confidence * 100).toFixed(1)}%)`);
        
        return {
          text: transcription,
          confidence: confidence,
          alternatives: alternatives.slice(1).map(alt => ({
            text: alt.transcript,
            confidence: alt.confidence || 0
          })),
          encoding: configVariant.encoding
        };
        
      } catch (configError) {
        Logger.warn(`Config ${configVariant.name} failed:`, configError.message);
        lastError = configError;
        continue;
      }
    }
    
    throw lastError || new Error('All transcription configs failed');
    
  } catch (error) {
    Logger.error('Google Speech transcription failed', error);
    
    if (error.message?.includes('Audio file too')) {
      throw error;
    }
    
    if (error.code === 11 || error.message?.includes('INVALID_ARGUMENT')) {
      throw new Error('Invalid audio format - LINE audio may be corrupted');
    }
    
    throw error;
  }
}

// ============================================================================
// SMART AI CORRECTION - ONLY WHEN NEEDED
// ============================================================================

async function smartAICorrection(rawText, confidence, stockCache, customerCache) {
  try {
    // ‚úÖ CRITICAL FIX: Only use AI if confidence is LOW or text looks suspicious
    const needsCorrection = 
      confidence < 0.75 || // Low confidence
      !hasValidProductName(rawText, stockCache) || // No product found
      !hasValidCustomerName(rawText, customerCache); // No customer found
    
    if (!needsCorrection) {
      Logger.info(`‚úÖ Transcription looks good (${(confidence * 100).toFixed(1)}%) - skipping AI correction`);
      return {
        corrected: rawText,
        confidence: 'high',
        changes: '‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç - ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß'
      };
    }
    
    Logger.info(`ü§ñ AI correction needed (confidence: ${(confidence * 100).toFixed(1)}%)`);

    const allProducts = stockCache.slice(0, 50).map(p => p.item).join('\n');
    const allCustomers = customerCache.slice(0, 30).map(c => c.name).join('\n');

    const schema = {
      type: 'object',
      properties: {
        corrected_text: {
          type: 'string',
          description: '‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß'
        },
        confidence: {
          type: 'string',
          enum: ['high', 'medium', 'low']
        },
        changes: {
          type: 'string',
          description: '‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç'
        }
      },
      required: ['corrected_text', 'confidence', 'changes']
    };

    const prompt = `‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ AI ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏ö‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á

üì¶ ‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö:
${allProducts}

üë• ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö:
${allCustomers}

üé§ ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á:
"${rawText}"

‡∏á‡∏≤‡∏ô:
1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÅ‡∏•‡∏∞‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
2. ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ú‡∏¥‡∏î‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
3. **‡∏≠‡∏¢‡πà‡∏≤‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß**
4. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡πÉ‡∏à ‡∏≠‡∏¢‡πà‡∏≤‡πÅ‡∏Å‡πâ

‡∏Å‡∏é‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:
- ‡∏ñ‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°
- ‡πÅ‡∏Å‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î
- ‡πÄ‡∏Å‡πá‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á: [‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤] ‡∏™‡∏±‡πà‡∏á [‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤] [‡∏à‡∏≥‡∏ô‡∏ß‡∏ô]
- ‡πÄ‡∏û‡∏¥‡πà‡∏° "‡∏™‡∏±‡πà‡∏á‡πÇ‡∏î‡∏¢ [‡∏Ñ‡∏ô]" ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:
Input: "‡∏û‡∏µ‡πà‡∏Å‡∏≤‡πÅ‡∏ü ‡∏™‡∏±‡πà‡∏á‡∏ô‡πâ‡∏≥‡πÅ‡∏Ç‡πá‡∏á‡∏ö‡∏î 2 ‡∏ñ‡∏∏‡∏á"
Output: {
  corrected_text: "‡∏û‡∏µ‡πà‡∏Å‡∏≤‡πÅ‡∏ü ‡∏™‡∏±‡πà‡∏á‡∏ô‡πâ‡∏≥‡πÅ‡∏Ç‡πá‡∏á‡∏ö‡∏î 2 ‡∏ñ‡∏∏‡∏á",
  confidence: "high",
  changes: "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç"
}

‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON`;

    const result = await generateWithGemini(prompt, schema, 0.1);

    Logger.success(`‚úÖ AI: "${rawText}" ‚Üí "${result.corrected_text}"`);
    Logger.info(`Changes: ${result.changes}`);

    return {
      corrected: result.corrected_text,
      confidence: result.confidence,
      changes: result.changes
    };

  } catch (error) {
    Logger.error('AI correction failed', error);
    return {
      corrected: rawText,
      confidence: 'low',
      changes: '‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç'
    };
  }
}

// ============================================================================
// HELPER: CHECK IF TEXT HAS VALID PRODUCT
// ============================================================================

function hasValidProductName(text, stockCache) {
  const results = stockVectorStore.search(text, 1);
  return results.length > 0 && results[0].similarity > 0.5;
}

// ============================================================================
// HELPER: CHECK IF TEXT HAS VALID CUSTOMER
// ============================================================================

function hasValidCustomerName(text, customerCache) {
  const normalizedText = text.toLowerCase();
  return customerCache.some(customer => 
    normalizedText.includes(customer.name.toLowerCase())
  );
}

// ============================================================================
// PROCESS VOICE MESSAGE (FIXED)
// ============================================================================

async function processVoiceMessage(audioBuffer) {
  const MIN_CONFIDENCE = configManager.get('VOICE_MIN_CONFIDENCE', 0.5);
  const MIN_TEXT_LENGTH = configManager.get('VOICE_MIN_TEXT_LENGTH', 3);
  
  try {
    Logger.info('üé§ Processing voice with Google Speech...');
    
    if (!audioBuffer || audioBuffer.length === 0) {
      return {
        success: false,
        error: '‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏î‡πâ\n‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÉ‡∏´‡∏°‡πà'
      };
    }
    
    // Step 1: Transcribe with Google
    const transcriptionResult = await transcribeAudioWithGoogle(audioBuffer);
    
    Logger.info(`Raw: "${transcriptionResult.text}" (${(transcriptionResult.confidence * 100).toFixed(1)}%)`);
    Logger.info(`Encoding used: ${transcriptionResult.encoding}`);
    
    if (!transcriptionResult.text || transcriptionResult.text.trim().length < MIN_TEXT_LENGTH) {
      let errorMsg = 'üé§ ‡∏ü‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ä‡∏±‡∏î ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏û‡∏π‡∏î‡πÉ‡∏´‡∏°‡πà\n\nüí° ‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö:\n';
      errorMsg += '‚Ä¢ ‡∏û‡∏π‡∏î‡∏ä‡∏±‡∏î‡πÜ ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô\n';
      errorMsg += '‚Ä¢ ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏á‡∏µ‡∏¢‡∏ö\n';
      errorMsg += '‚Ä¢ ‡∏ñ‡∏∑‡∏≠‡πÑ‡∏°‡∏Ñ‡πå‡πÉ‡∏Å‡∏•‡πâ‡∏õ‡∏≤‡∏Å\n';
      errorMsg += '‚Ä¢ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: "‡∏û‡∏µ‡πà‡∏Å‡∏≤‡πÅ‡∏ü ‡∏™‡∏±‡πà‡∏á‡∏ô‡πâ‡∏≥‡πÅ‡∏Ç‡πá‡∏á‡∏´‡∏•‡∏≠‡∏î‡πÉ‡∏´‡∏ç‡πà 2 ‡∏ñ‡∏∏‡∏á"';
      
      return {
        success: false,
        error: errorMsg
      };
    }
    
    // Step 2: Smart AI correction (only when needed)
    const stockCache = getStockCache();
    const customerCache = getCustomerCache();
    
    const aiCorrected = await smartAICorrection(
      transcriptionResult.text,
      transcriptionResult.confidence,
      stockCache,
      customerCache
    );
    
    Logger.success(`‚úÖ Final: "${aiCorrected.corrected}"`);
    
    // Step 3: Build warning
    let warning = null;
    
    if (transcriptionResult.confidence < MIN_CONFIDENCE) {
      warning = '‚ö†Ô∏è ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á';
    } else if (aiCorrected.confidence === 'low') {
      warning = `‚ÑπÔ∏è AI ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡πÉ‡∏à: ${aiCorrected.changes}`;
    } else if (aiCorrected.confidence === 'medium' && aiCorrected.changes !== '‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç' && aiCorrected.changes !== '‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç - ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß') {
      warning = `‚ÑπÔ∏è ${aiCorrected.changes}`;
    }
    
    if (transcriptionResult.alternatives && transcriptionResult.alternatives.length > 0 && 
        transcriptionResult.confidence < 0.7) {
      warning = (warning || '') + '\n\nüîÑ ‡∏ó‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏∑‡πà‡∏ô:\n';
      transcriptionResult.alternatives.slice(0, 2).forEach((alt, idx) => {
        warning += `${idx + 2}. "${alt.text}" (${(alt.confidence * 100).toFixed(1)}%)\n`;
      });
    }
    
    return {
      success: true,
      text: aiCorrected.corrected,
      original: transcriptionResult.text,
      confidence: transcriptionResult.confidence,
      aiConfidence: aiCorrected.confidence,
      changes: aiCorrected.changes,
      warning,
      encoding: transcriptionResult.encoding
    };
    
  } catch (error) {
    Logger.error('Voice processing failed', error);
    
    if (error.message?.includes('Audio file too small')) {
      return {
        success: false,
        error: '‚ùå ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏•‡πá‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ\n‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏´‡πâ‡∏¢‡∏≤‡∏ß‡∏Å‡∏ß‡πà‡∏≤‡∏ô‡∏µ‡πâ'
      };
    }
    
    if (error.message?.includes('Audio file too large')) {
      return {
        success: false,
        error: '‚ùå ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ\n‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡πâ‡∏ô‡∏•‡∏á'
      };
    }
    
    if (error.message?.includes('quota') || error.message?.includes('429')) {
      return {
        success: false,
        error: '‚è≥ ‡∏£‡∏∞‡∏ö‡∏ö‡∏¢‡∏∏‡πà‡∏á ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏≠ 1-2 ‡∏ô‡∏≤‡∏ó‡∏µ\n‡∏´‡∏£‡∏∑‡∏≠‡∏•‡∏≠‡∏á‡∏û‡∏¥‡∏°‡∏û‡πå‡πÅ‡∏ó‡∏ô'
      };
    }
    
    if (error.message?.includes('Invalid audio') || error.message?.includes('corrupted')) {
      return {
        success: false,
        error: '‚ùå ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á\n‡∏•‡∏≠‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÉ‡∏´‡∏°‡πà‡∏´‡∏£‡∏∑‡∏≠‡∏û‡∏¥‡∏°‡∏û‡πå‡πÅ‡∏ó‡∏ô‡∏Ñ‡πà‡∏∞'
      };
    }
    
    if (error.code === 11 || error.message?.includes('INVALID_ARGUMENT')) {
      return {
        success: false,
        error: '‚ùå ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö\n‡∏•‡∏≠‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÉ‡∏´‡∏°‡πà‡∏´‡∏£‡∏∑‡∏≠‡∏û‡∏¥‡∏°‡∏û‡πå‡πÅ‡∏ó‡∏ô‡∏Ñ‡πà‡∏∞'
      };
    }
    
    return {
      success: false,
      error: '‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î\n‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏´‡∏£‡∏∑‡∏≠‡∏û‡∏¥‡∏°‡∏û‡πå‡πÅ‡∏ó‡∏ô‡∏Ñ‡πà‡∏∞\n\n' + 
              `‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î: ${error.message?.substring(0, 100)}`
    };
  }
}

// ============================================================================
// FETCH AUDIO FROM LINE
// ============================================================================

async function fetchAudioFromLine(messageId) {
  try {
    const LINE_TOKEN = configManager.get('LINE_TOKEN');
    
    Logger.info(`Fetching audio from LINE: ${messageId}`);
    
    const response = await fetch(
      `https://api-data.line.me/v2/bot/message/${messageId}/content`,
      {
        headers: { 
          'Authorization': `Bearer ${LINE_TOKEN}` 
        },
        signal: AbortSignal.timeout(30000)
      }
    );

    if (!response.ok) {
      const errorText = await response.text();
      Logger.error(`LINE API error: ${response.status} - ${errorText}`);
      throw new Error(`LINE audio fetch failed: ${response.status} ${response.statusText}`);
    }

    const buffer = Buffer.from(await response.arrayBuffer());
    const sizeKB = (buffer.length / 1024).toFixed(1);
    
    Logger.success(`‚úÖ Audio fetched: ${sizeKB}KB`);
    
    if (buffer.length === 0) {
      throw new Error('LINE returned empty audio file');
    }
    
    if (buffer.length < 100) {
      throw new Error('LINE audio file too small (likely corrupt)');
    }
    
    return buffer;
  } catch (error) {
    Logger.error('Fetch audio from LINE failed', error);
    
    if (error.name === 'AbortError') {
      throw new Error('LINE audio download timeout - please try again');
    }
    
    throw new Error(`Failed to fetch LINE audio: ${error.message}`);
  }
}

// ============================================================================
// EXPORTS
// ============================================================================

module.exports = {
  processVoiceMessage,
  fetchAudioFromLine,
  initializeSpeechClient
};